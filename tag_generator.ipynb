{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process data & feature extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import corpora, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How is viewport size typically passed as an ar...</td>\n",
       "      <td>I'm looking at the docs for a command line too...</td>\n",
       "      <td>&lt;html&gt;&lt;web&gt;&lt;command-line&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mysqli_query insert success and throws error</td>\n",
       "      <td>This issue has baffled me. I have a simple mys...</td>\n",
       "      <td>&lt;php&gt;&lt;mysqli&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  How is viewport size typically passed as an ar...   \n",
       "1       mysqli_query insert success and throws error   \n",
       "\n",
       "                                                body  \\\n",
       "0  I'm looking at the docs for a command line too...   \n",
       "1  This issue has baffled me. I have a simple mys...   \n",
       "\n",
       "                        tags  \n",
       "0  <html><web><command-line>  \n",
       "1              <php><mysqli>  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read sample data\n",
    "df = pd.read_csv('input/stack_ds_4_9_2017 .csv',sep=',',quotechar='|',header=None)\n",
    "df.columns = ['title','body','tags']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**notice that the data is already filtered with code and images etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4533 entries, 0 to 4532\n",
      "Data columns (total 3 columns):\n",
      "title    4533 non-null object\n",
      "body     4533 non-null object\n",
      "tags     4533 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 106.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How is viewport size typically passed as an ar...</td>\n",
       "      <td>&lt;html&gt;&lt;web&gt;&lt;command-line&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mysqli_query insert success and throws error T...</td>\n",
       "      <td>&lt;php&gt;&lt;mysqli&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  How is viewport size typically passed as an ar...   \n",
       "1  mysqli_query insert success and throws error T...   \n",
       "\n",
       "                        tags  \n",
       "0  <html><web><command-line>  \n",
       "1              <php><mysqli>  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge title and body so that we only have one feature to consider\n",
    "merged = [ title + ' ' + body for title, body in zip(df.title,df.body)]\n",
    "df_merged = pd.DataFrame({'content':merged,'tags':df.tags})\n",
    "df_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3591 out of 4533\n"
     ]
    }
   ],
   "source": [
    "# how many tags we have?\n",
    "all_tags = df.tags.apply(lambda x: x.replace('<','').split('>'))\n",
    "all_tags = [x for x in list(itertools.chain(*all_tags)) if x ]\n",
    "ct = Counter(all_tags)\n",
    "print(len(ct),'out of',len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tokenize **\n",
    "- lowercase \n",
    "- topwords\n",
    "- remove if not character\n",
    "- stemming (seems not that good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_be_removed = set(stopwords.words('english'))\n",
    "tokenizer = lambda x : [word.lower() for word in word_tokenize(re.sub(\"[^a-zA-Z]\",\" \",x)) if word.lower() not in to_be_removed]\n",
    "# tokenizer = lambda x : [ SnowballStemmer('english').stem(word.lower()) for word in word_tokenize(re.sub(\"[^a-zA-Z]\",\" \",x)) if word.lower() not in to_be_removed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**apply tf-idf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.72 s, sys: 12 ms, total: 2.73 s\n",
      "Wall time: 2.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# para to be tweaked, we start from a simple one\n",
    "tfidf = TfidfVectorizer(min_df=0.001,max_df=0.95, max_features=None, tokenizer= tokenizer, ngram_range=(1,2))\n",
    "tfidf_trained = tfidf.fit_transform(list(df_merged.content))\n",
    "\n",
    "df_tfidf = pd.DataFrame({'token':tfidf.get_feature_names(),'tfidf_value':tfidf.idf_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>7.6276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue code</th>\n",
       "      <td>7.6276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invisible</th>\n",
       "      <td>7.6276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invoke native</th>\n",
       "      <td>7.6276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ios swift</th>\n",
       "      <td>7.6276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfidf_value\n",
       "token                     \n",
       "aa                  7.6276\n",
       "issue code          7.6276\n",
       "invisible           7.6276\n",
       "invoke native       7.6276\n",
       "ios swift           7.6276"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.sort_values('tfidf_value',ascending=False).set_index('token').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**simple LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a look up dict, where every unique word is mapped to a unique int\n",
    "texts = df_merged.content.apply(tokenizer)\n",
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 2),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:10] # first 10 words in first sentence : word 0 occurs once, word 8 occurs twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 0 ns, total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# id2word: required. The LdaModel class requires our previous dictionary to map ids to strings.\n",
    "# passes: optional. The number of laps the model will take through corpus. The greater the number of passes, the more accurate the model will be. A lot of passes can be slow on a very large corpus.\n",
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics=3, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"file\" + 0.010*\"using\" + 0.010*\"error\" + 0.007*\"app\" + 0.006*\"code\" + 0.006*\"server\" + 0.006*\"get\" + 0.006*\"use\" + 0.006*\"java\" + 0.005*\"application\"'),\n",
       " (1,\n",
       "  '0.011*\"code\" + 0.010*\"like\" + 0.009*\"using\" + 0.009*\"data\" + 0.009*\"want\" + 0.008*\"get\" + 0.006*\"value\" + 0.006*\"one\" + 0.005*\"use\" + 0.005*\"table\"'),\n",
       " (2,\n",
       "  '0.109*\"gt\" + 0.104*\"lt\" + 0.026*\"class\" + 0.025*\"div\" + 0.012*\"li\" + 0.009*\"p\" + 0.008*\"span\" + 0.006*\"amp\" + 0.006*\"img\" + 0.006*\"src\"')]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=3, num_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "well, interesting! did't expect this, we can clearly see that first topic is about ' java application' sencond 'data science' and third 'web programming' :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.19550704690128598),\n",
       "  (1, 0.53599704209050969),\n",
       "  (2, 0.26849591100820436)],\n",
       " [(0, 0.19588895201654802), (1, 0.79898438185014875)],\n",
       " [(0, 0.36679144274699133), (1, 0.62486013772567239)],\n",
       " [(1, 0.98937853198442927)],\n",
       " [(0, 0.986926102923949)],\n",
       " [(0, 0.47525538856717775), (1, 0.519279176261919)],\n",
       " [(0, 0.32184300478390188), (1, 0.67265188639212181)],\n",
       " [(0, 0.11058666899631907),\n",
       "  (1, 0.64263933851495258),\n",
       "  (2, 0.24677399248872836)],\n",
       " [(1, 0.99371624335500575)],\n",
       " [(0, 0.86465473159512529),\n",
       "  (1, 0.12393820858975782),\n",
       "  (2, 0.011407059815116921)],\n",
       " [(0, 0.52755204648382714), (1, 0.46272688182800692)],\n",
       " [(1, 0.96025351674437598), (2, 0.032153327054220047)],\n",
       " [(1, 0.98592532477743444)],\n",
       " [(0, 0.87275044247265332),\n",
       "  (1, 0.017909980661175162),\n",
       "  (2, 0.10933957686617148)],\n",
       " [(0, 0.78338215150403812), (1, 0.20859400565970859)],\n",
       " [(0, 0.30884184967608569), (1, 0.68339444486673051)],\n",
       " [(0, 0.29340659218600079), (1, 0.43244814095424161), (2, 0.2741452668597576)],\n",
       " [(0, 0.32236661433936847),\n",
       "  (1, 0.66645972444365709),\n",
       "  (2, 0.011173661216974396)],\n",
       " [(0, 0.013373357547112214),\n",
       "  (1, 0.9745934493189784),\n",
       "  (2, 0.012033193133909338)],\n",
       " [(0, 0.011630283299328911),\n",
       "  (1, 0.97718614396742176),\n",
       "  (2, 0.011183572733249309)]]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each document has several topics\n",
    "[ldamodel.get_document_topics(corpus)[i] for i in range(20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[lda source](https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "- remove verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problems:\n",
    "- propagate tags from LDA ? increase error? is this necessary?\n",
    "- lda is really slow even on a small part of data\n",
    "- will deep learning be possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
